{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1570575193704,
     "user": {
      "displayName": "JiaLang Huang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYM6NxavIxqUmyuz6xQEdZ5ujhFanJDA4xPXJB=s64",
      "userId": "15621513465289356626"
     },
     "user_tz": 240
    },
    "id": "Tglsm50YkCLW",
    "outputId": "d90095c7-eb27-4cb4-b011-2f68cc776f02"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1570575194738,
     "user": {
      "displayName": "JiaLang Huang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYM6NxavIxqUmyuz6xQEdZ5ujhFanJDA4xPXJB=s64",
      "userId": "15621513465289356626"
     },
     "user_tz": 240
    },
    "id": "RJ9AQoP4j9tm",
    "outputId": "a43316b6-0f92-484d-ab73-b7b670778997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Jialang/Google Drive/Colab Notebooks/CSE474HW2/data/fashion\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "path = ''\n",
    "if os.path.isdir('/content/drive/My Drive/Colab Notebooks/CSE474HW2/data/fashion'):#on ghoogle drive\n",
    "     path = '/content/drive/My Drive/Colab Notebooks/CSE474HW2/data/fashion'\n",
    "elif os.path.isdir('C:/Users/Jialang/Google Drive/Colab Notebooks/CSE474HW2/data/fashion'): #on local\n",
    "     path ='C:/Users/Jialang/Google Drive/Colab Notebooks/CSE474HW2/data/fashion'\n",
    "elif os.path.isdir('C:/Users/JiaLang\\' Desktop/Google Drive/Colab Notebooks/CSE474HW2/data (1)/fashion'):\n",
    "     path = 'C:/Users/JiaLang\\' Desktop/Google Drive/Colab Notebooks/CSE474HW2/data (1)/fashion'\n",
    "    \n",
    "    \n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 412,
     "status": "error",
     "timestamp": 1570575253908,
     "user": {
      "displayName": "JiaLang Huang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYM6NxavIxqUmyuz6xQEdZ5ujhFanJDA4xPXJB=s64",
      "userId": "15621513465289356626"
     },
     "user_tz": 240
    },
    "id": "5t42mpMMj9tr",
    "outputId": "33ed0dd4-9905-4399-b74c-8bb34aecd338"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Jialang/Google Drive/Colab Notebooks/CSE474HW2/data/fashion\n"
     ]
    }
   ],
   "source": [
    "# Read Fashion MNIST dataset\n",
    "\n",
    "import sys\n",
    "\n",
    "import util_mnist_reader\n",
    "print(path)\n",
    "X_train, y_train = util_mnist_reader.load_mnist(path, kind='train')\n",
    "X_test, y_test = util_mnist_reader.load_mnist(path, kind='t10k')\n",
    "\n",
    "# Your code goes here . . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1284,
     "status": "error",
     "timestamp": 1570575159599,
     "user": {
      "displayName": "JiaLang Huang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYM6NxavIxqUmyuz6xQEdZ5ujhFanJDA4xPXJB=s64",
      "userId": "15621513465289356626"
     },
     "user_tz": 240
    },
    "id": "9C-zShfqj9tu",
    "outputId": "4e2bde6b-1584-4dfc-93de-2a5b47a6c21a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784)\n",
      "(60000,) (10000,)\n",
      "60000 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x299b54f38d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage.util import img_as_float\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(y_train.shape,y_test.shape)\n",
    "print(len(y_train),len(y_test))\n",
    "plt.imshow(X_train[480].reshape(28,28),cmap='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J61g-EePj9t2"
   },
   "outputs": [],
   "source": [
    "#sigmoid function\n",
    "def sigmoid(z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "\n",
    "#softmax function \n",
    "def softmax(z):\n",
    "    max_z = np.max(z,axis=0,keepdims=True)\n",
    "    exp_z = np.exp(z-max_z)\n",
    "    return_z = exp_z/np.sum(exp_z,axis = 0,keepdims = True)\n",
    "    return return_z\n",
    "#activation function: ReLU\n",
    "def ReLU(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "#function to compute the loss for the one hiiden layer model\n",
    "def compute_multiclass_loss(Y, Y_hat):\n",
    "\n",
    "    L_sum = np.sum(np.multiply(Y, np.log(Y_hat)))\n",
    "    m = Y.shape[1]\n",
    "    L = -(1/m) * L_sum\n",
    "\n",
    "    return L\n",
    "\n",
    "# to compute the accuracy after the predicted the data\n",
    "def compareAccurcy(y_test,y_pred):\n",
    "    accuracy =0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i] == y_pred[i]:\n",
    "            accuracy +=1\n",
    "    \n",
    "    return accuracy/len(y_test)\n",
    "\n",
    "#to predict after trainind\n",
    "def predict_new(W1,W2,b1,b2,X):\n",
    "    Z1 = np.matmul(W1,X) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.matmul(W2,A1) + b2\n",
    "    A2 = softmax(Z2)#np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n",
    "    return A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zE1iG1S7j9t6"
   },
   "outputs": [],
   "source": [
    "#show the train accaucy and validation accurcay vs number of epochs, train loss and validation loss vs number of epochs \n",
    "def plotGraph(train_losstrack,valid_losstrack,train_acc,valid_acc,learning_rate,hidden_units):\n",
    "        epochs = range(len(train_losstrack))\n",
    "        plt.figure(figsize=(15,5))\n",
    "        \n",
    "        \n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(epochs, train_acc, 'green', label='Training accuracy')\n",
    "        plt.plot(epochs, valid_acc, 'red', label='Validation accuracy')\n",
    "        plt.xlabel('Number of epochs')\n",
    "        plt.title(\"Training and validation accuracy at learning rate: %.3f, hidden units:%d\"%(learning_rate,hidden_units))\n",
    "        plt.legend()\n",
    "        #plt.figure()\n",
    "        \n",
    "        plt.subplot(2,2,2)\n",
    "        plt.plot(epochs, train_losstrack, 'green', label='Training loss')\n",
    "        plt.plot(epochs, valid_losstrack, 'red', label='Validation loss')\n",
    "        plt.xlabel('Number of epochs')\n",
    "        plt.title(\"Training and validation loss at learning rate: %.3f, hidden units: %d\"%(learning_rate,hidden_units))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "#model for one hidden layer\n",
    "#training set, validation set, epochs, learning rate, and the number of hidden units\n",
    "def one_hidden_layer(train_X,train_Y,vali_X,vali_y,epochs,learning_rate,hidden_units):\n",
    "   \n",
    "    #initial all parameter\n",
    "    input_size = train_X.shape[0]\n",
    "    hidden_layer_units = hidden_units\n",
    "    output_size = 10\n",
    "    \n",
    "    Y_vali = vali_y\n",
    "    X_vali = vali_X\n",
    "    \n",
    "    X = train_X\n",
    "    Y = train_Y\n",
    "    \n",
    "    train_losstrack = []\n",
    "    valid_losstrack = []\n",
    "    \n",
    "    train_acc = []\n",
    "    valid_acc = []\n",
    "    \n",
    "    #length of the input\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    #hidden layer\n",
    "    W1 =  np.random.randn(hidden_layer_units,input_size,)#width,depth \n",
    "    b1 = np.zeros((hidden_layer_units,1))\n",
    "    \n",
    "    #output layer\n",
    "    W2 =  np.random.randn(output_size,hidden_layer_units)\n",
    "    b2 = np.zeros((output_size,1))\n",
    "    \n",
    "    N,D = train_X.shape\n",
    "    \n",
    "    for epoch in range(epochs+1):\n",
    "        \n",
    "        #forward:\n",
    "        Z1 = np.matmul(W1,X) + b1\n",
    "        A1 = sigmoid(Z1)\n",
    "        Z2 = np.matmul(W2,A1) + b2\n",
    "        A2 = softmax(Z2)#np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n",
    "        \n",
    "        #loss function\n",
    "        cost = compute_multiclass_loss(Y, A2)\n",
    "        train_losstrack.append(cost)\n",
    "        tra_acc = compareAccurcy(np.argmax(A2,axis=0),np.argmax(Y,axis=0))\n",
    "        train_acc.append(tra_acc)\n",
    "        \n",
    "        #Backpropogation\n",
    "        dZ2 = A2-Y\n",
    "        dW2 = (1./m) * np.matmul(dZ2, A1.T)\n",
    "        db2 = (1./m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "        dA1 = np.matmul(W2.T, dZ2)\n",
    "        dZ1 = dA1 * sigmoid(Z1) * (1 - sigmoid(Z1))\n",
    "        dW1 = (1./m) * np.matmul(dZ1, X.T)\n",
    "        db1 = (1./m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "        W2 = W2 - learning_rate * dW2\n",
    "        b2 = b2 - learning_rate * db2\n",
    "        W1 = W1 - learning_rate * dW1\n",
    "        b1 = b1 - learning_rate * db1\n",
    "        \n",
    "        \n",
    "        ## to validate the data\n",
    "        pre_vali = predict_new(W1,W2,b1,b2,vali_X)\n",
    "        vali_cost = compute_multiclass_loss(Y_vali, pre_vali)\n",
    "        va_acc = compareAccurcy(np.argmax(pre_vali,axis=0),np.argmax(Y_vali,axis=0))\n",
    "        valid_losstrack.append(vali_cost)\n",
    "        valid_acc.append(va_acc)\n",
    "\n",
    "        if(epoch % 10 == 0):\n",
    "            print(\"Epoch: %d/%d, train cost: %.3f, valid cost: %.3f, train acc: %.3f, valid acc: %.3f\"%(epoch,epochs,cost,vali_cost,tra_acc,va_acc))\n",
    "        \n",
    "    \n",
    "    return W1,W2,b1,b2,train_losstrack,valid_losstrack,train_acc,valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784) (12000, 784) (48000,) (12000,)\n"
     ]
    }
   ],
   "source": [
    "#seperate the train data into train and validarion, 80% for training and 20% for validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "snn_train_X,snn_valid_X,snn_train_label,snn_valid_label = train_test_split(X_train, y_train, test_size=0.2, random_state=13)\n",
    "print(snn_train_X.shape,snn_valid_X.shape,snn_train_label.shape,snn_valid_label.shape)\n",
    "\n",
    "#normalize the data set\n",
    "snn_train_X = snn_train_X/255\n",
    "snn_valid_X = snn_valid_X/255\n",
    "\n",
    "#train data\n",
    "n_Ytrain = snn_train_label.shape[0]\n",
    "snn_Y_train = snn_train_label.reshape(1,n_Ytrain)\n",
    "snn_Y_train = np.eye(10)[snn_train_label.astype('int32')]\n",
    "snn_Y_train = snn_Y_train.T.reshape(10,n_Ytrain)\n",
    "\n",
    "\n",
    "#vali data\n",
    "n_Yvali = snn_valid_label.shape[0]\n",
    "snn_Y_vali = snn_valid_label.reshape(1,n_Yvali)\n",
    "snn_Y_vali = np.eye(10)[snn_valid_label.astype('int32')]\n",
    "snn_Y_vali = snn_Y_vali.T.reshape(10,n_Yvali)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TJhbTYZNj9t8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_hidden_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-348f0916e3ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#train the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_acc\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mone_hidden_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msnn_train_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msnn_Y_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msnn_valid_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msnn_Y_vali\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'one_hidden_layer' is not defined"
     ]
    }
   ],
   "source": [
    "#set up the hyper-parameter\n",
    "epochs = 1000\n",
    "learning_rate = 0.65\n",
    "hidden_units = 128\n",
    "\n",
    "#train the data\n",
    "w1,w2,b1,b2,loss,valid_loss,acc,valid_acc= one_hidden_layer(snn_train_X.T,snn_Y_train,snn_valid_X.T,snn_Y_vali,epochs,learning_rate,hidden_units)\n",
    "\n",
    "\n",
    "#show a graph\n",
    "plotGraph(loss,valid_loss,acc,valid_acc,learning_rate,hidden_units)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.805\n"
     ]
    }
   ],
   "source": [
    "#normalize the data set\n",
    "snn_test_X = X_test/255\n",
    "\n",
    "\n",
    "#train data\n",
    "n_Ytest = y_test.shape[0]\n",
    "snn_Y_test = y_test.reshape(1,n_Ytest)\n",
    "snn_Y_test = np.eye(10)[y_test.astype('int32')]\n",
    "snn_Y_test = snn_Y_test.T.reshape(10,n_Ytest)\n",
    "\n",
    "\n",
    "test_pred = predict_new(w1,w2,b1,b2,snn_test_X.T)\n",
    "test_acc = compareAccurcy(np.argmax(snn_Y_test ,axis=0),np.argmax(test_pred,axis=0))\n",
    "\n",
    "print(\"Test accuracy:%.3f\"%(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48000, 784), (12000, 784), (48000, 10), (12000, 10))"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multi-layer nerual network\n",
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "# normalize the data set\n",
    "MNN_train_Y = to_categorical(y_train)\n",
    "MNN_test_Y= to_categorical(y_test)\n",
    "\n",
    "MNN_train_X = X_train.astype('float32')\n",
    "MNN_test_X = X_test.astype('float32')\n",
    "MNN_train_X = MNN_train_X / 255.\n",
    "MNN_test_X = MNN_test_X / 255.\n",
    "\n",
    "#seperate the data into train data and vali data\n",
    "from sklearn.model_selection import train_test_split\n",
    "MNN_train_X,MNN_valid_X,MNN_train_label,MNN_valid_label = train_test_split(MNN_train_X, MNN_train_Y, test_size=0.2, random_state=10)\n",
    "MNN_train_X.shape,MNN_valid_X.shape,MNN_train_label.shape,MNN_valid_label.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pkq8Zj5Vj9uG",
    "outputId": "8f695c42-6c3c-473a-eb0f-488c53337be7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jialang\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "#Multi-Layer Neural Network Model\n",
    "class MNN_model():\n",
    "    #initial the model\n",
    "    def __init__ (self):\n",
    "        self.my_model = Sequential()\n",
    "        self.batch_size = 200\n",
    "        self.epochs = 20\n",
    "        self.lr = 0.5\n",
    "        self.num_class = 10\n",
    "        self.num_hidden = 1\n",
    "        self.num_hidden_units = 200\n",
    "        self.optimizer = keras.optimizers.Adam()\n",
    "        self.activationfunction = 'sigmoid'\n",
    "        \n",
    "    # change learning rate, batch size,epochs,active function, number of hidden layers and number of each hidden layer's units\n",
    "    def setHyper_parameter(self,lr,batch_size,epochs,active_fun,number_hidden,hidden_units):\n",
    "        self.lr = lr \n",
    "        self.batch_size = batch_size \n",
    "        self.epochs = epochs \n",
    "        self.optimizer = keras.optimizers.SGD(lr = self.lr,momentum=0.0,nesterov=False)\n",
    "        self.activationfunction = active_fun\n",
    "        self.num_hidden = number_hidden\n",
    "        self.num_hidden_units = hidden_units\n",
    "    \n",
    "    #train the model\n",
    "    def train_model(self,train_X,train_label,valid_x,valid_label):\n",
    "        self.my_model = Sequential()\n",
    "        \n",
    "        # Add an input layer \n",
    "        self.my_model.add(Dense(self.num_hidden_units, activation=self.activationfunction, input_shape=(784,)))\n",
    "\n",
    "        # Add hidden layers \n",
    "        for i in range(self.num_hidden):\n",
    "            self.my_model.add(Dense(self.num_hidden_units, activation=self.activationfunction))\n",
    "\n",
    "        # Add an output layer \n",
    "        self.my_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "        # train the data\n",
    "        self.my_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=self.optimizer,metrics=['accuracy'])\n",
    "        #self.train_model = self.my_model.fit(train_X, train_label, batch_size=self.batch_size,epochs=self.epochs,verbose=1,validation_data=(valid_x,valid_label))\n",
    "        \n",
    "        \n",
    "    #Function to plot the graph of training loss vs number of epochs while training \n",
    "    #and training accuracy vs number of epochs       \n",
    "    def showGraph(self):\n",
    "        accuracy = self.train_model.history['acc']\n",
    "        val_accuracy = self.train_model.history['val_acc']\n",
    "        loss = self.train_model.history['loss']\n",
    "        val_loss = self.train_model.history['val_loss']\n",
    "        epochs = range(len(accuracy))\n",
    "        plt.figure(figsize=(15,5))\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "        plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "        plt.xlabel('Number of epochs')\n",
    "        plt.title(\"Training and validation accuracy at learning rate: %.3f, batch size:%d\"%(self.lr,self.batch_size))\n",
    "        plt.legend()\n",
    "        #plt.figure()\n",
    "        \n",
    "        plt.subplot(2,2,2)\n",
    "        plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "        plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "        plt.xlabel('Number of epochs')\n",
    "        plt.title(\"Training and validation loss at learning rate: %.3f, batch size:%d\"%(self.lr,self.batch_size))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    #function to predict the test data\n",
    "    def predict(self,mnn_test_x,mnn_test_label):\n",
    "        test_eval = self.my_model.evaluate(mnn_test_x, mnn_test_label, verbose=1)\n",
    "        print('Test loss:', test_eval[0])\n",
    "        print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MNN_train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c0949d1fb38f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mmy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMNN_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetHyper_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactive_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumber_hidden_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumber_hidden_units\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMNN_train_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mMNN_train_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mMNN_valid_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mMNN_valid_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mmy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mMNN_test_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mMNN_test_Y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MNN_train_X' is not defined"
     ]
    }
   ],
   "source": [
    "#train the data via multi-layer neural network model\n",
    "#set up the hyper-parameters\n",
    "learning_rate = 0.35\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "active_function = 'sigmoid'\n",
    "number_hidden_layers = 3\n",
    "number_hidden_units = 200\n",
    "\n",
    "\n",
    "#create a Multi-layer Neural Network\n",
    "my = MNN_model()\n",
    "my.setHyper_parameter(learning_rate ,batch_size,epochs,active_function,number_hidden_layers,number_hidden_units)\n",
    "my.train_model(MNN_train_X,MNN_train_label,MNN_valid_X,MNN_valid_label)\n",
    "my.showGraph()\n",
    "MNN_test_X.shape,MNN_test_Y.shape\n",
    "my.predict(MNN_test_X,MNN_test_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolution neural network model\n",
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "class CNN_model():\n",
    "    def __init__ (self):\n",
    "        self.my_model = Sequential()\n",
    "        self.batch_size = 200\n",
    "        self.epochs = 20\n",
    "        self.lr = 0.5\n",
    "        self.num_class = 10\n",
    "        self.optimizer = keras.optimizers.Adam()\n",
    "        self.activationfunction = 'sigmoid'\n",
    "        \n",
    "    \n",
    "    def setHyper_parameter(self,lr,batch_size,epochs,active_fun):\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.optimizer = keras.optimizers.SGD(lr = self.lr,momentum=0.0,nesterov=False)\n",
    "        self.activationfunction = active_fun \n",
    "    \n",
    "    def train_model(self,train_X,train_label,valid_x,valid_label):\n",
    "        self.my_model = Sequential()\n",
    "        #input conv2d\n",
    "        self.my_model.add(Conv2D(64, kernel_size=(2, 2),activation=self.activationfunction,input_shape=(28,28,1),padding='same'))\n",
    "        self.my_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "        \n",
    "        #hidden conv2d\n",
    "        self.my_model.add(Conv2D(32, (2, 2), activation=self.activationfunction,padding='same'))\n",
    "        self.my_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "        #output dense\n",
    "        self.my_model.add(Flatten())\n",
    "        self.my_model.add(Dense(256, activation='sigmoid'))             \n",
    "        self.my_model.add(Dense(self.num_class, activation='softmax'))\n",
    "        \n",
    "        \n",
    "        self.my_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=self.optimizer,metrics=['accuracy'])\n",
    "        self.train_model = self.my_model.fit(train_X, train_label, batch_size=self.batch_size,epochs=self.epochs,verbose=1,validation_data=(valid_X, valid_label))\n",
    "    \n",
    "    def showGraph(self):\n",
    "        accuracy = self.train_model.history['acc']\n",
    "        val_accuracy = self.train_model.history['val_acc']\n",
    "        loss = self.train_model.history['loss']\n",
    "        val_loss = self.train_model.history['val_loss']\n",
    "        epochs = range(len(accuracy))\n",
    "        plt.figure(figsize=(15,5))\n",
    "        \n",
    "        plt.subplot(1,2,1)\n",
    "        plt.xlabel('Number of epochs')\n",
    "        plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "        plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "        plt.title(\"Training and validation accuracy at learning rate: %.3f, batch size:%d\"%(self.lr,self.batch_size))\n",
    "        plt.legend()\n",
    "       \n",
    "        plt.subplot(1,2,2)\n",
    "        plt.xlabel('Number of epochs')\n",
    "        plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "        plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "        plt.title(\"Training and validation loss at learning rate: %.3f, batch size:%d\"%(self.lr,self.batch_size))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    def predict(self,test_x,test_label):\n",
    "        test_eval = self.my_model.evaluate(test_X, test_label, verbose=1)\n",
    "        print('Test loss:', test_eval[0])\n",
    "        print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jialang\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\Jialang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"C:\\Users\\Jialang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"C:\\Users\\Jialang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"C:\\Users\\Jialang\\Anaconda3\\lib\\imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"C:\\Users\\Jialang\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: DLL load failed: The specified module could not be found.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0m_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\imp.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(name, file, filename, details)\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[1;34m(name, path, file)\u001b[0m\n\u001b[0;32m    342\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[1;32m--> 343\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified module could not be found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-338-d76568767ae8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## reshape the data for CNN model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Globally-importable utils.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcomponent_api_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[1;32m---> 74\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\Jialang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"C:\\Users\\Jialang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"C:\\Users\\Jialang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"C:\\Users\\Jialang\\Anaconda3\\lib\\imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"C:\\Users\\Jialang\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: DLL load failed: The specified module could not be found.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "## reshape and normalize the data for CNN model\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "cnn_train_X= X_train\n",
    "cnn_train_Y = y_train\n",
    "\n",
    "cnn_test_X = X_test\n",
    "cnn_test_Y = y_test\n",
    "\n",
    "cnn_train_X = cnn_train_X.reshape(-1, 28,28, 1)\n",
    "cnn_test_X = cnn_test_X.reshape(-1, 28,28, 1)\n",
    "cnn_train_X.shape, cnn_train_X.shape\n",
    "\n",
    "# Change the labels from categorical to one-hot encoding\n",
    "cnn_train_Y = to_categorical(cnn_train_Y)\n",
    "cnn_test_Y = to_categorical(cnn_test_Y)\n",
    "\n",
    "\n",
    "cnn_train_X = cnn_train_X.astype('float32')\n",
    "cnn_test_X = cnn_test_X.astype('float32')\n",
    "cnn_train_X = cnn_train_X / 255.\n",
    "cnn_test_X = cnn_test_X / 255.\n",
    "\n",
    "#seperate the data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "cnn_train_X,cnn_valid_X,cnn_train_label,cnn_valid_label = train_test_split(cnn_train_X, cnn_train_Y, test_size=0.2, random_state=13)\n",
    "cnn_train_X.shape,cnn_valid_X.shape,cnn_train_label.shape,cnn_valid_label.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 20s 406us/step - loss: 2.3218 - acc: 0.0985 - val_loss: 2.3028 - val_acc: 0.0992\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 11s 236us/step - loss: 2.3038 - acc: 0.1012 - val_loss: 2.3062 - val_acc: 0.0993\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 10s 206us/step - loss: 1.5015 - acc: 0.4201 - val_loss: 0.7067 - val_acc: 0.7208\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 10s 200us/step - loss: 0.6102 - acc: 0.7681 - val_loss: 0.5528 - val_acc: 0.7930\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 9s 182us/step - loss: 0.5135 - acc: 0.8072 - val_loss: 0.4850 - val_acc: 0.8229\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 8s 168us/step - loss: 0.4626 - acc: 0.8284 - val_loss: 0.4595 - val_acc: 0.8348\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 8s 166us/step - loss: 0.4297 - acc: 0.8431 - val_loss: 0.4160 - val_acc: 0.8517\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 8s 160us/step - loss: 0.4072 - acc: 0.8493 - val_loss: 0.4251 - val_acc: 0.8508\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 0.3914 - acc: 0.8565 - val_loss: 0.3850 - val_acc: 0.8644\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 10s 204us/step - loss: 0.3747 - acc: 0.8613 - val_loss: 0.3736 - val_acc: 0.8665\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 11s 232us/step - loss: 0.3617 - acc: 0.8665 - val_loss: 0.3673 - val_acc: 0.8666\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 11s 238us/step - loss: 0.3521 - acc: 0.8698 - val_loss: 0.3588 - val_acc: 0.8691\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 12s 245us/step - loss: 0.3422 - acc: 0.8736 - val_loss: 0.3741 - val_acc: 0.8615\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 11s 228us/step - loss: 0.3340 - acc: 0.8757 - val_loss: 0.3503 - val_acc: 0.8728\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 10s 202us/step - loss: 0.3270 - acc: 0.8779 - val_loss: 0.3335 - val_acc: 0.8784\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 11s 222us/step - loss: 0.3185 - acc: 0.8818 - val_loss: 0.3450 - val_acc: 0.8732\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 11s 228us/step - loss: 0.3124 - acc: 0.8831 - val_loss: 0.3348 - val_acc: 0.8764\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 11s 225us/step - loss: 0.3062 - acc: 0.8857 - val_loss: 0.3471 - val_acc: 0.8740\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 11s 226us/step - loss: 0.3037 - acc: 0.8858 - val_loss: 0.3279 - val_acc: 0.8794\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 10s 208us/step - loss: 0.2958 - acc: 0.8890 - val_loss: 0.3274 - val_acc: 0.8806\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 9s 198us/step - loss: 0.2933 - acc: 0.8899 - val_loss: 0.3250 - val_acc: 0.8805\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 10s 212us/step - loss: 0.2869 - acc: 0.8925 - val_loss: 0.3253 - val_acc: 0.8827\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 11s 228us/step - loss: 0.2839 - acc: 0.8942 - val_loss: 0.3175 - val_acc: 0.8815\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 10s 207us/step - loss: 0.2791 - acc: 0.8956 - val_loss: 0.3323 - val_acc: 0.8802\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================] - 11s 230us/step - loss: 0.2737 - acc: 0.8973 - val_loss: 0.3225 - val_acc: 0.8802\n",
      "Epoch 26/100\n",
      "48000/48000 [==============================] - 11s 235us/step - loss: 0.2702 - acc: 0.8980 - val_loss: 0.3154 - val_acc: 0.8859\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================] - 11s 230us/step - loss: 0.2673 - acc: 0.8983 - val_loss: 0.3049 - val_acc: 0.8870\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================] - 12s 240us/step - loss: 0.2628 - acc: 0.9006 - val_loss: 0.3288 - val_acc: 0.8788\n",
      "Epoch 29/100\n",
      "48000/48000 [==============================] - 10s 211us/step - loss: 0.2581 - acc: 0.9027 - val_loss: 0.3015 - val_acc: 0.8898\n",
      "Epoch 30/100\n",
      "48000/48000 [==============================] - 10s 218us/step - loss: 0.2549 - acc: 0.9049 - val_loss: 0.3249 - val_acc: 0.8822\n",
      "Epoch 31/100\n",
      "48000/48000 [==============================] - 11s 220us/step - loss: 0.2516 - acc: 0.9051 - val_loss: 0.3039 - val_acc: 0.8879\n",
      "Epoch 32/100\n",
      "48000/48000 [==============================] - 11s 219us/step - loss: 0.2480 - acc: 0.9072 - val_loss: 0.2991 - val_acc: 0.8904\n",
      "Epoch 33/100\n",
      "48000/48000 [==============================] - 10s 213us/step - loss: 0.2452 - acc: 0.9064 - val_loss: 0.3055 - val_acc: 0.8881\n",
      "Epoch 34/100\n",
      "48000/48000 [==============================] - 10s 198us/step - loss: 0.2410 - acc: 0.9085 - val_loss: 0.2917 - val_acc: 0.8935\n",
      "Epoch 35/100\n",
      "48000/48000 [==============================] - 10s 214us/step - loss: 0.2375 - acc: 0.9106 - val_loss: 0.2946 - val_acc: 0.8928\n",
      "Epoch 36/100\n",
      "48000/48000 [==============================] - 11s 225us/step - loss: 0.2340 - acc: 0.9111 - val_loss: 0.2855 - val_acc: 0.8947\n",
      "Epoch 37/100\n",
      "48000/48000 [==============================] - 11s 220us/step - loss: 0.2304 - acc: 0.9123 - val_loss: 0.3024 - val_acc: 0.8922\n",
      "Epoch 38/100\n",
      "48000/48000 [==============================] - 11s 226us/step - loss: 0.2274 - acc: 0.9135 - val_loss: 0.3021 - val_acc: 0.8907\n",
      "Epoch 39/100\n",
      "48000/48000 [==============================] - 10s 214us/step - loss: 0.2245 - acc: 0.9158 - val_loss: 0.2934 - val_acc: 0.8902\n",
      "Epoch 40/100\n",
      "48000/48000 [==============================] - 11s 223us/step - loss: 0.2209 - acc: 0.9165 - val_loss: 0.2881 - val_acc: 0.8953\n",
      "Epoch 41/100\n",
      "48000/48000 [==============================] - 11s 232us/step - loss: 0.2166 - acc: 0.9184 - val_loss: 0.2912 - val_acc: 0.8920\n",
      "Epoch 42/100\n",
      "48000/48000 [==============================] - 11s 230us/step - loss: 0.2148 - acc: 0.9200 - val_loss: 0.2875 - val_acc: 0.8954\n",
      "Epoch 43/100\n",
      "48000/48000 [==============================] - 11s 237us/step - loss: 0.2125 - acc: 0.9200 - val_loss: 0.2867 - val_acc: 0.8966\n",
      "Epoch 44/100\n",
      "48000/48000 [==============================] - 11s 223us/step - loss: 0.2094 - acc: 0.9207 - val_loss: 0.2924 - val_acc: 0.8948\n",
      "Epoch 45/100\n",
      "48000/48000 [==============================] - 9s 188us/step - loss: 0.2046 - acc: 0.9225 - val_loss: 0.2831 - val_acc: 0.8979\n",
      "Epoch 46/100\n",
      "48000/48000 [==============================] - 8s 170us/step - loss: 0.2037 - acc: 0.9227 - val_loss: 0.2814 - val_acc: 0.9012\n",
      "Epoch 47/100\n",
      "48000/48000 [==============================] - 8s 159us/step - loss: 0.2017 - acc: 0.9229 - val_loss: 0.2843 - val_acc: 0.9000\n",
      "Epoch 48/100\n",
      "48000/48000 [==============================] - 7s 153us/step - loss: 0.1981 - acc: 0.9237 - val_loss: 0.2798 - val_acc: 0.8992\n",
      "Epoch 49/100\n",
      "48000/48000 [==============================] - 8s 157us/step - loss: 0.1948 - acc: 0.9255 - val_loss: 0.2843 - val_acc: 0.8973\n",
      "Epoch 50/100\n",
      "48000/48000 [==============================] - 8s 157us/step - loss: 0.1925 - acc: 0.9270 - val_loss: 0.2777 - val_acc: 0.9017\n",
      "Epoch 51/100\n",
      "48000/48000 [==============================] - 9s 183us/step - loss: 0.1894 - acc: 0.9276 - val_loss: 0.2820 - val_acc: 0.9003\n",
      "Epoch 52/100\n",
      "48000/48000 [==============================] - 8s 170us/step - loss: 0.1876 - acc: 0.9283 - val_loss: 0.2919 - val_acc: 0.8968\n",
      "Epoch 53/100\n",
      "48000/48000 [==============================] - 8s 168us/step - loss: 0.1834 - acc: 0.9304 - val_loss: 0.2932 - val_acc: 0.8971\n",
      "Epoch 54/100\n",
      "48000/48000 [==============================] - 8s 165us/step - loss: 0.1803 - acc: 0.9306 - val_loss: 0.2979 - val_acc: 0.8948\n",
      "Epoch 55/100\n",
      "48000/48000 [==============================] - 10s 217us/step - loss: 0.1797 - acc: 0.9321 - val_loss: 0.2921 - val_acc: 0.8983\n",
      "Epoch 56/100\n",
      "48000/48000 [==============================] - 11s 229us/step - loss: 0.1750 - acc: 0.9335 - val_loss: 0.2966 - val_acc: 0.8973\n",
      "Epoch 57/100\n",
      "48000/48000 [==============================] - 11s 230us/step - loss: 0.1736 - acc: 0.9344 - val_loss: 0.2855 - val_acc: 0.9015\n",
      "Epoch 58/100\n",
      "48000/48000 [==============================] - 11s 234us/step - loss: 0.1716 - acc: 0.9345 - val_loss: 0.2796 - val_acc: 0.9028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "48000/48000 [==============================] - 11s 231us/step - loss: 0.1684 - acc: 0.9372 - val_loss: 0.2925 - val_acc: 0.8989\n",
      "Epoch 60/100\n",
      "48000/48000 [==============================] - 9s 196us/step - loss: 0.1645 - acc: 0.9367 - val_loss: 0.2942 - val_acc: 0.8990\n",
      "Epoch 61/100\n",
      "48000/48000 [==============================] - 10s 218us/step - loss: 0.1646 - acc: 0.9379 - val_loss: 0.2903 - val_acc: 0.9004\n",
      "Epoch 62/100\n",
      "48000/48000 [==============================] - 11s 229us/step - loss: 0.1618 - acc: 0.9380 - val_loss: 0.3013 - val_acc: 0.8986\n",
      "Epoch 63/100\n",
      "48000/48000 [==============================] - 11s 229us/step - loss: 0.1586 - acc: 0.9401 - val_loss: 0.2912 - val_acc: 0.9026\n",
      "Epoch 64/100\n",
      "48000/48000 [==============================] - 12s 244us/step - loss: 0.1569 - acc: 0.9411 - val_loss: 0.2892 - val_acc: 0.9010\n",
      "Epoch 65/100\n",
      "48000/48000 [==============================] - 11s 225us/step - loss: 0.1536 - acc: 0.9420 - val_loss: 0.2891 - val_acc: 0.9018\n",
      "Epoch 66/100\n",
      "48000/48000 [==============================] - 11s 227us/step - loss: 0.1500 - acc: 0.9437 - val_loss: 0.2853 - val_acc: 0.9038\n",
      "Epoch 67/100\n",
      "48000/48000 [==============================] - 11s 231us/step - loss: 0.1502 - acc: 0.9437 - val_loss: 0.3047 - val_acc: 0.9001\n",
      "Epoch 68/100\n",
      "48000/48000 [==============================] - 11s 231us/step - loss: 0.1470 - acc: 0.9453 - val_loss: 0.2924 - val_acc: 0.9016\n",
      "Epoch 69/100\n",
      "48000/48000 [==============================] - 10s 213us/step - loss: 0.1454 - acc: 0.9454 - val_loss: 0.3196 - val_acc: 0.8932\n",
      "Epoch 70/100\n",
      "48000/48000 [==============================] - 12s 240us/step - loss: 0.1412 - acc: 0.9468 - val_loss: 0.3017 - val_acc: 0.8991\n",
      "Epoch 71/100\n",
      "48000/48000 [==============================] - 12s 252us/step - loss: 0.1391 - acc: 0.9468 - val_loss: 0.2973 - val_acc: 0.9008\n",
      "Epoch 72/100\n",
      "48000/48000 [==============================] - 12s 251us/step - loss: 0.1372 - acc: 0.9478 - val_loss: 0.2977 - val_acc: 0.9011\n",
      "Epoch 73/100\n",
      "48000/48000 [==============================] - 13s 269us/step - loss: 0.1342 - acc: 0.9498 - val_loss: 0.2935 - val_acc: 0.9037\n",
      "Epoch 74/100\n",
      "48000/48000 [==============================] - 12s 248us/step - loss: 0.1351 - acc: 0.9495 - val_loss: 0.3143 - val_acc: 0.8952\n",
      "Epoch 75/100\n",
      "48000/48000 [==============================] - 11s 229us/step - loss: 0.1321 - acc: 0.9498 - val_loss: 0.2957 - val_acc: 0.9020\n",
      "Epoch 76/100\n",
      "48000/48000 [==============================] - 11s 230us/step - loss: 0.1272 - acc: 0.9523 - val_loss: 0.3131 - val_acc: 0.8999\n",
      "Epoch 77/100\n",
      "48000/48000 [==============================] - 10s 214us/step - loss: 0.1251 - acc: 0.9526 - val_loss: 0.2935 - val_acc: 0.9029\n",
      "Epoch 78/100\n",
      "48000/48000 [==============================] - 11s 223us/step - loss: 0.1232 - acc: 0.9539 - val_loss: 0.2969 - val_acc: 0.9026\n",
      "Epoch 79/100\n",
      "48000/48000 [==============================] - 11s 228us/step - loss: 0.1219 - acc: 0.9545 - val_loss: 0.3064 - val_acc: 0.9008\n",
      "Epoch 80/100\n",
      "48000/48000 [==============================] - 11s 221us/step - loss: 0.1193 - acc: 0.9557 - val_loss: 0.3419 - val_acc: 0.8906\n",
      "Epoch 81/100\n",
      "48000/48000 [==============================] - 11s 230us/step - loss: 0.1164 - acc: 0.9570 - val_loss: 0.3132 - val_acc: 0.9003\n",
      "Epoch 82/100\n",
      "48000/48000 [==============================] - 10s 214us/step - loss: 0.1143 - acc: 0.9577 - val_loss: 0.3025 - val_acc: 0.9039\n",
      "Epoch 83/100\n",
      "48000/48000 [==============================] - 10s 205us/step - loss: 0.1114 - acc: 0.9591 - val_loss: 0.3052 - val_acc: 0.9038\n",
      "Epoch 84/100\n",
      "48000/48000 [==============================] - 11s 223us/step - loss: 0.1112 - acc: 0.9593 - val_loss: 0.3012 - val_acc: 0.9039\n",
      "Epoch 85/100\n",
      "48000/48000 [==============================] - 11s 220us/step - loss: 0.1065 - acc: 0.9618 - val_loss: 0.3340 - val_acc: 0.8973\n",
      "Epoch 86/100\n",
      "48000/48000 [==============================] - 11s 219us/step - loss: 0.1060 - acc: 0.9616 - val_loss: 0.3222 - val_acc: 0.9005\n",
      "Epoch 87/100\n",
      "48000/48000 [==============================] - 11s 238us/step - loss: 0.1038 - acc: 0.9627 - val_loss: 0.3344 - val_acc: 0.8973\n",
      "Epoch 88/100\n",
      "48000/48000 [==============================] - 10s 199us/step - loss: 0.1023 - acc: 0.9628 - val_loss: 0.3236 - val_acc: 0.9002\n",
      "Epoch 89/100\n",
      "48000/48000 [==============================] - 8s 167us/step - loss: 0.0985 - acc: 0.9642 - val_loss: 0.3215 - val_acc: 0.9018\n",
      "Epoch 90/100\n",
      "48000/48000 [==============================] - 8s 156us/step - loss: 0.0996 - acc: 0.9639 - val_loss: 0.3112 - val_acc: 0.9063\n",
      "Epoch 91/100\n",
      "48000/48000 [==============================] - 7s 154us/step - loss: 0.0957 - acc: 0.9654 - val_loss: 0.3192 - val_acc: 0.9014\n",
      "Epoch 92/100\n",
      "48000/48000 [==============================] - 8s 163us/step - loss: 0.0939 - acc: 0.9666 - val_loss: 0.3176 - val_acc: 0.9033\n",
      "Epoch 93/100\n",
      "48000/48000 [==============================] - 8s 168us/step - loss: 0.0918 - acc: 0.9678 - val_loss: 0.3306 - val_acc: 0.9001\n",
      "Epoch 94/100\n",
      "48000/48000 [==============================] - 8s 165us/step - loss: 0.0901 - acc: 0.9679 - val_loss: 0.3302 - val_acc: 0.8999\n",
      "Epoch 95/100\n",
      "48000/48000 [==============================] - 8s 163us/step - loss: 0.0882 - acc: 0.9689 - val_loss: 0.3349 - val_acc: 0.8995\n",
      "Epoch 96/100\n",
      "48000/48000 [==============================] - 8s 164us/step - loss: 0.0860 - acc: 0.9693 - val_loss: 0.3232 - val_acc: 0.9041\n",
      "Epoch 97/100\n",
      "48000/48000 [==============================] - 10s 207us/step - loss: 0.0838 - acc: 0.9705 - val_loss: 0.3396 - val_acc: 0.9001\n",
      "Epoch 98/100\n",
      "48000/48000 [==============================] - 11s 226us/step - loss: 0.0825 - acc: 0.9705 - val_loss: 0.3340 - val_acc: 0.9032\n",
      "Epoch 99/100\n",
      "48000/48000 [==============================] - 11s 221us/step - loss: 0.0804 - acc: 0.9722 - val_loss: 0.3315 - val_acc: 0.9050\n",
      "Epoch 100/100\n",
      "48000/48000 [==============================] - 11s 227us/step - loss: 0.0801 - acc: 0.9710 - val_loss: 0.3637 - val_acc: 0.8957\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 231us/step\n",
      "Test loss: 0.3849374195381999\n",
      "Test accuracy: 0.8905\n"
     ]
    }
   ],
   "source": [
    "#set the hyper-parameter\n",
    "learning_rate = 0.4\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "my = CNN_model()\n",
    "my.setHyper_parameter(learning_rate,batch_size,epochs,'sigmoid')\n",
    "my.train_model(cnn_train_X,cnn_train_label,cnn_valid_X,cnn_valid_label)\n",
    "my.showGraph()\n",
    "my.predict(cnn_test_X,cnn_test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "cse.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
